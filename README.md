# ðŸ§­ AI Risk Navigator

**AI Risk Navigator** is a Retrieval-Augmented Generation (RAG) chatbot that enables contextual Q&A over internal risk, compliance, and policy PDFs. Powered by OpenAI's GPT models, SentenceTransformers, ChromaDB, FastAPI, and Streamlit, it provides explainable, source-grounded answers for high-stakes domains.

This project is featured in the book _From Code to Conscious: Navigating the Ethical AI Landscape_, and demonstrates how LLMs can be ethically leveraged to assist in AI-powered risk management.

---

## ðŸ“‘ Table of Contents

- [Demo](#demo)
- [Architecture Overview](#architecture-overview)
- [Project Structure](#project-structure)
- [Setup Instructions](#setup-instructions)
- [Running the Project](#running-the-project)
- [Usage](#usage)
- [Challenges & Next Steps](#challenges--next-steps)

---

## ðŸš€ Demo

<p align="center">
  <img src="screenshots/demo.png" alt="AI Risk Navigator Chatbot Demo" width="80%">
</p>

- Ask risk-related questions like:
  > â€œWhat are the GDPR retention rules for transaction data?â€
- View real-time responses with inline citations.
- Explore source documents directly via the UI.

---

## ðŸ§  Architecture Overview

**AI Risk Navigator** is composed of 5 core modules:

1. **PDF Processor**  
   Extracts, chunks, and tokenizes long policy or regulatory documents.

2. **Embedder**  
   Converts chunks into semantic vectors using `all-MiniLM-L6-v2`.

3. **Vector Store (ChromaDB)**  
   Stores and retrieves top-k document chunks relevant to user queries.

4. **LLM Generator**  
   Constructs a contextual prompt from retrieved chunks and generates a grounded response using OpenAIâ€™s GPT (`o1-mini`, `gpt-3.5-turbo`, etc.).

5. **Frontend (Streamlit)**  
   Displays the chat interface, conversation history, and document sources.

---

## ðŸ“ Project Structure

```
AI-Risk-Navigator/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                  # FastAPI endpoint (/chat)
â”‚   â”œâ”€â”€ document_processor.py    # PDF loading, chunking
â”‚   â”œâ”€â”€ chroma_manager.py        # Vector DB interface
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                   # Streamlit UI
â”œâ”€â”€ data/                        # PDF transcripts or policy docs
â”œâ”€â”€ chroma_db/                   # Persisted vector database
â”œâ”€â”€ .env                         # API keys and paths
â”œâ”€â”€ Dockerfile                   # Image config
â”œâ”€â”€ docker-compose.yml          # Multi-container setup
â””â”€â”€ requirements.txt            # Python dependencies
```

---

## âš™ï¸ Setup Instructions

1. **Clone the repository**

```bash
git clone https://github.com/your-username/AI-Risk-Navigator.git
cd AI-Risk-Navigator
```

2. **Create a `.env` file**

```env
OPENAI_API_KEY=your-openai-key
OPENAI_MODEL=o1-mini
DOCS_PATH=/app/data
CHROMA_DIR=/app/chroma_db
API_URL=http://backend:8000/chat
```

3. **Add your documents**

Place your PDF files in the `./data/` directory.

---

## â–¶ï¸ Running the Project

Make sure you have Docker installed, then run:

```bash
docker-compose up --build
```

Access the chatbot at:

- **Frontend:** [http://localhost:8501](http://localhost:8501)  
- **API Docs:** [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ðŸ’¬ Usage

1. Enter your question in the input box (e.g., _"Whatâ€™s the retention policy for financial records?"_).
2. The chatbot retrieves relevant chunks from the indexed PDFs.
3. GPT generates a response using the retrieved context.
4. Expand **Sources Used** to view citation metadata.

---

## âš ï¸ Challenges & Next Steps

- Improve chunking strategy to better preserve semantic boundaries
- Add real-time document upload and re-indexing
- Optimize latency with asynchronous embedding + retrieval
- Extend to multimodal documents (e.g., scanned PDFs with OCR)
- Introduce user access control and audit logging

---

> Built as part of my book(co-authored) *From Code to Conscious: Navigating the Ethical AI Landscape* â€” demonstrating ethical, explainable AI in high-risk domains.
